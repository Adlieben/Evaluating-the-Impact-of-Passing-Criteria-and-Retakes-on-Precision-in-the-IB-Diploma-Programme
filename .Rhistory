"spexssp2tz0xxxx",
"busmthp1tz1xxxx", "busmthp1tz2xxxx",
"busmthp2tz1xxxx", "busmthp2tz2xxxx",
"busmtsp1tz1xxxx", "busmtsp1tz2xxxx",
"busmtsp2tz1xxxx", "busmtsp2tz2xxxx",
"chemihp3tz1xxxx", "chemihp3tz2xxxx",
"chemisp3tz1xxxx", "chemisp3tz2xxxx",
"clgrssp1tz0xxxx",
"clgrssp2tz0xxxx",
"greekhp2tz0xxxx",
"greeksp2tz0xxxx",
"hconbsp2tz0xxxx",
"histxbp1tz0xxxx", "histxbp2tz1xxxx", "histxbp2tz2xxxx",
"histxhp3tz0afxx", "histxhp3tz0amxx", "histxhp3tz0euxx", "histxhp3tz0ocxx",
"mhkazsp2tz0xxxx",
"philobp2tz0xxxx",
"philohp1tz1xxxx", "philohp1tz2xxxx",
"philosp1tz1xxxx", "philosp1tz2xxxx",
"polthsp2tz0xxxx",
"psychhp2tz0xxxx",
"psychsp2tz0xxxx",
"socanhp1tz0xxxx",
"socanhp2tz0xxxx",
"socansp1tz0xxxx",
"socansp2tz0xxxx",
"turkssp2tz0xxxx",
"wldresp2tz0xxxx"
)
# Join with the anonymization key
nl_key_clean <- nl_key %>%
mutate(Original_lower = str_trim(tolower(Original)))
mapped_df <- data.frame(NO_LANG_CODE = no_lang_codes) %>%
left_join(nl_key_clean, by = c("NO_LANG_CODE" = "Original_lower"))
# View the result
print(mapped_df)
write.csv(mapped_df, 'mapped.csv')
setwd('A. Data/C. November data')
setwd('A. Data/C. November data')
component_data_n <- read_csv("N23 component data.csv")
setwd('A. Data/C.November data')
setwd('A. Data/C. November data')
setwd("../C. November data")
component_data_n <- read_csv("N23 component data.csv")
grade_boundaries_n <- read_csv("N23 component grade boundaries.csv")
View(component_data_n)
component_data_n <- read_csv("N23 component data.csv")[,-1]
component_data_n <- read_csv("N23 component data.csv", header = TRUE)[,-1]
component_data_n <- read_csv("N23 component data.csv", header = F)[,-1]
component_data_n <- read_csv("N23 component data.csv", header = FALSE)[,-1]
component_data_n <- read.csv("N23 component data.csv")[,-1]
grade_boundaries_n <- read.csv("N23 component grade boundaries.csv")[,-1]
scaling_factors_n <- read.csv("N23 scaling factors.csv")
subject_boundaries_n <- read.csv("N23 subject boundaries.csv")[,-1]
View(component_data_n)
component_data <- read.csv("M23 component data.csv", header = TRUE, sep="")
setwd('../A. May data')
component_data <- read.csv("M23 component data.csv", header = TRUE, sep="")
colnames(component_data_n ) <- colnames(component_data)[1:27]
component_data_n <- read.csv("N23 component data.csv")
setwd("../C. November data")
component_data_n <- read.csv("N23 component data.csv")
colnames(component_data_n ) <- colnames(component_data)[1:27]
grade_boundaries_n <- read.csv("N23 component grade boundaries.csv")[,-1]
scaling_factors_n <- read.csv("N23 scaling factors.csv")
subject_boundaries_n <- read.csv("N23 subject boundaries.csv")[,-1]
View(scaling_factors_n)
scaling_factors_n <- read.csv("N23 scaling factors.csv", sep = ";")
grade_boundaries_n <- read.csv("N23 component grade boundaries.csv")[,-1]
scaling_factors_n <- read.csv("N23 scaling factors.csv", sep = ";")
subject_boundaries_n <- read.csv("N23 subject boundaries.csv")[,-1]
View(subject_boundaries_n)
subject_boundaries <- read.csv("M23 subject boundaries.csv")
View(subject_boundaries)
subject_boundaries_n <- subject_boundaries_n %>% select(-SUBJECT)
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
names(component_data_n)
component_data_n <- read.csv("N23 component data.csv")[, -c(6,7)]
colnames(component_data_n ) <- colnames(component_data)[1:27]
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
component_grade_boundaries_n <- read.csv("N23 component grade boundaries.csv")[,-1]
View(component_grade_boundaries)
View(component_grade_boundaries_n)
component_data <- component_data %>% select(-c(SUBJECT, COMPONENT))
component_data <- component_data %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
component_grade_boundaries <- component_grade_boundaries %>% select(-c(SCALING_FACTOR, NEW_UPPER_BOUNDARY, OLD_UPPER_BOUNDARY))
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
# 1. Remove useless identifying columns ----
component_data <- component_data %>% select(-c(SUBJECT, COMPONENT))
component_data <- component_data %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
component_grade_boundaries <- component_grade_boundaries %>% select(-c(SCALING_FACTOR, NEW_UPPER_BOUNDARY, OLD_UPPER_BOUNDARY))
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
subject_boundaries <- subject_boundaries %>% select(-OLD_SUBJECT_UPPER_BOUNDARY)
subject_boundaries_n <- subject_boundaries_n %>% select(-SUBJECT)
component_grade_boundaries_n <- component_grade_boundaries_n %>% select(-November)
View(scaling_factors_n)
component_data_n <- component_data_n %>% select(-c(SUBJECT, COMPONENT))
scaling_factors_n <- scaling_factors_n %>% select(-c(SUBJECT, COMPONENT))
subject_boundaries_n <- replace_subjects(subject_boundaries_n, "SUBJECT_OPTION", subject_key)
component_grade_boundaries_n <- replace_subjects(component_grade_boundaries_n, "SUBJECT_OPTION", subject_key)
component_data_n <- replace_subjects(component_data_n, "SUBJECT_OPTION", subject_key)
component_grade_boundaries_n <- replace_nl(component_grade_boundaries_n, "NO_LANG_CODE", nl_key)
component_data_n <- replace_nl(component_data_n, "NO_LANG_CODE", nl_key)
View(component_data_n)
View(component_data_n)
component_data_n$LANGUAGE <- replace_language(component_data_n$LANGUAGE, language_key)
component_data_n <- replace_components(component_data_n, "PAPER_CODE", component_key)
component_grade_boundaries_n <- replace_components(component_grade_boundaries_n, "PAPER_CODE", component_key)
scaling_factors_n <- replace_components(scaling_factors_n, "PAPER_CODE", component_key)
scaling_factors_n <- replace_subjects(scaling_factors_n, "SUBJECT_OPTION", subject_key)
caling_factors_n$LANGUAGE <- replace_language(scaling_factors_n$LANGUAGE, language_key)
scaling_factors_n$LANGUAGE <- replace_language(scaling_factors_n$LANGUAGE, language_key)
scaling_factors_n$LANGUAGE <- replace_language(scaling_factors_n$LANGUAGE, language_key)
View(scaling_factors_n)
new_subjects <- setdiff(unique(c(
subject_boundaries_n$SUBJECT_OPTION,
component_grade_boundaries_n$SUBJECT_OPTION,
component_data_n$SUBJECT_OPTION,
scaling_factors_n$SUBJECT_OPTION
)), subject_key$Original)
if (length(new_subjects) > 0) {
new_subject_map <- data.frame(
Original = new_subjects,
Anonymized = paste0("Sub", seq(nrow(subject_key) + 1, nrow(subject_key) + length(new_subjects))),
stringsAsFactors = FALSE
)
subject_key <- rbind(subject_key, new_subject_map)
}
# May
setwd('../A. May data') # Not good practice, done for speed here
# May
setwd('A. Data/A. May data') # Not good practice, done for speed here
component_data <- read.csv("M23 component data.csv", header = TRUE, sep="")
component_grade_boundaries <- read.csv("M23 component grade boundaries.csv")
item_data <- read.csv("M23 item data.csv")
subject_boundaries <- read.csv("M23 subject boundaries.csv")
# November
setwd("../C. November data")
component_data_n <- read.csv("N23 component data.csv")[, -c(6,7)]
colnames(component_data_n ) <- colnames(component_data)[1:27]
component_grade_boundaries_n <- read.csv("N23 component grade boundaries.csv")[,-1]
scaling_factors_n <- read.csv("N23 scaling factors.csv", sep = ";")
subject_boundaries_n <- read.csv("N23 subject boundaries.csv")[,-1]
# 1. Remove useless identifying columns ----
component_data <- component_data %>% select(-c(SUBJECT, COMPONENT))
component_data <- component_data %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
component_grade_boundaries <- component_grade_boundaries %>% select(-c(SCALING_FACTOR, NEW_UPPER_BOUNDARY, OLD_UPPER_BOUNDARY))
component_data_n <- component_data_n %>% select(-c(SUBJECT, COMPONENT))
component_data_n <-  component_data_n %>% select(-c(RAW_MARK, SCALED_MARK, COMPONENT_GRADE, SUBJECT_GRADE,
PREDICTED_GRADE, TOTAL_SCALED, MARKS_TO_NEXT_GRADE, TOTAL_POINTS, EE_TOK_BONUS_POINTS))
subject_boundaries <- subject_boundaries %>% select(-OLD_SUBJECT_UPPER_BOUNDARY)
subject_boundaries_n <- subject_boundaries_n %>% select(-SUBJECT)
component_grade_boundaries_n <- component_grade_boundaries_n %>% select(-November)
scaling_factors_n <- scaling_factors_n %>% select(-c(SUBJECT, COMPONENT))
# 2. Remove subject ----
# Step 1: Get all unique subject names from the three datasets
all_subjects <- unique(c(
subject_boundaries$SUBJECT_OPTION,
component_grade_boundaries$SUBJECT_OPTION,
component_data$SUBJECT_OPTION
))
# Step 2: Shuffle and assign anonymized names
set.seed(123)  # for reproducibility
shuffled_subjects <- sample(all_subjects)
anonymized_names <- paste0("Sub", seq_along(shuffled_subjects))
subject_key <- data.frame(
Original = shuffled_subjects,
Anonymized = anonymized_names,
stringsAsFactors = FALSE
)
# Step 3: Replace subject names in all datasets
replace_subjects <- function(df, col_name, key_df) {
df[[col_name]] <- key_df$Anonymized[match(df[[col_name]], key_df$Original)]
return(df)
}
new_subjects <- setdiff(unique(c(
subject_boundaries_n$SUBJECT_OPTION,
component_grade_boundaries_n$SUBJECT_OPTION,
component_data_n$SUBJECT_OPTION,
scaling_factors_n$SUBJECT_OPTION
)), subject_key$Original)
if (length(new_subjects) > 0) {
new_subject_map <- data.frame(
Original = new_subjects,
Anonymized = paste0("Sub", seq(nrow(subject_key) + 1, nrow(subject_key) + length(new_subjects))),
stringsAsFactors = FALSE
)
subject_key <- rbind(subject_key, new_subject_map)
}
subject_boundaries <- replace_subjects(subject_boundaries, "SUBJECT_OPTION", subject_key)
component_grade_boundaries <- replace_subjects(component_grade_boundaries, "SUBJECT_OPTION", subject_key)
component_data <- replace_subjects(component_data, "SUBJECT_OPTION", subject_key)
subject_boundaries_n <- replace_subjects(subject_boundaries_n, "SUBJECT_OPTION", subject_key)
component_grade_boundaries_n <- replace_subjects(component_grade_boundaries_n, "SUBJECT_OPTION", subject_key)
component_data_n <- replace_subjects(component_data_n, "SUBJECT_OPTION", subject_key)
scaling_factors_n <- replace_subjects(scaling_factors_n, "SUBJECT_OPTION", subject_key)
# 3. Remove components ----
# Step 1: Get all unique PAPER_CODE values from both datasets
all_components <- unique(c(
component_data$PAPER_CODE,
component_grade_boundaries$PAPER_CODE
))
# Step 2: Shuffle and assign anonymized component names
set.seed(456)  # different seed for components
shuffled_components <- sample(all_components)
anonymized_components <- paste0("comp", seq_along(shuffled_components))
component_key <- data.frame(
Original = shuffled_components,
Anonymized = anonymized_components,
stringsAsFactors = FALSE
)
# Step 3: Replace PAPER_CODE values in relevant datasets
replace_components <- function(df, col_name, key_df) {
df[[col_name]] <- key_df$Anonymized[match(df[[col_name]], key_df$Original)]
return(df)
}
new_components <- setdiff(unique(c(
component_data_n$PAPER_CODE,
component_grade_boundaries_n$PAPER_CODE,
scaling_factors_n$PAPER_CODE
)), component_key$Original)
if (length(new_components) > 0) {
new_component_map <- data.frame(
Original = new_components,
Anonymized = paste0("comp", seq(nrow(component_key) + 1, nrow(component_key) + length(new_components))),
stringsAsFactors = FALSE
)
component_key <- rbind(component_key, new_component_map)
}
component_data <- replace_components(component_data, "PAPER_CODE", component_key)
component_grade_boundaries <- replace_components(component_grade_boundaries, "PAPER_CODE", component_key)
component_data_n <- replace_components(component_data_n, "PAPER_CODE", component_key)
component_grade_boundaries_n <- replace_components(component_grade_boundaries_n, "PAPER_CODE", component_key)
scaling_factors_n <- replace_components(scaling_factors_n, "PAPER_CODE", component_key)
# 4. Remove no_lang_codes ----
# Step 1: Extract all unique NO_LANG_CODE values from all three datasets
all_nl_codes <- unique(c(
component_grade_boundaries$NO_LANG_CODE,
component_data$NO_LANG_CODE,
item_data$NO_LANG_CODE
))
# Step 2: Shuffle and assign anonymized names
set.seed(789)  # different seed again for NO_LANG_CODE
shuffled_nl_codes <- sample(all_nl_codes)
anonymized_nl <- paste0("nl", seq_along(shuffled_nl_codes))
nl_key <- data.frame(
Original = shuffled_nl_codes,
Anonymized = anonymized_nl,
stringsAsFactors = FALSE
)
# Step 3: Replace NO_LANG_CODE values in all datasets
replace_nl <- function(df, col_name, key_df) {
df[[col_name]] <- key_df$Anonymized[match(df[[col_name]], key_df$Original)]
return(df)
}
new_nl_codes <- setdiff(unique(c(
component_grade_boundaries_n$NO_LANG_CODE,
component_data_n$NO_LANG_CODE
)), nl_key$Original)
if (length(new_nl_codes) > 0) {
new_nl_map <- data.frame(
Original = new_nl_codes,
Anonymized = paste0("nl", seq(nrow(nl_key) + 1, nrow(nl_key) + length(new_nl_codes))),
stringsAsFactors = FALSE
)
nl_key <- rbind(nl_key, new_nl_map)
}
component_grade_boundaries <- replace_nl(component_grade_boundaries, "NO_LANG_CODE", nl_key)
component_data <- replace_nl(component_data, "NO_LANG_CODE", nl_key)
item_data <- replace_nl(item_data, "NO_LANG_CODE", nl_key)
component_grade_boundaries_n <- replace_nl(component_grade_boundaries_n, "NO_LANG_CODE", nl_key)
# 5. Remove language ----
# Step 1: Collect all unique language values from all three columns
all_languages <- unique(c(
component_data$LANGUAGE,
component_data$LANGUAGE1,
component_data$LANGUAGE2
))
# Step 2: Remove any NAs (if applicable)
all_languages <- all_languages[!is.na(all_languages)]
# Step 3: Shuffle and assign anonymized labels
set.seed(321)  # fixed seed for reproducibility
shuffled_languages <- sample(all_languages)
anonymized_languages <- paste0("lang", seq_along(shuffled_languages))
language_key <- data.frame(
Original = shuffled_languages,
Anonymized = anonymized_languages,
stringsAsFactors = FALSE
)
# Step 4: Function to replace values in a column based on the key
replace_language <- function(col, key_df) {
key_df$Anonymized[match(col, key_df$Original)]
}
new_languages <- setdiff(unique(scaling_factors_n$LANGUAGE), language_key$Original)
new_languages <- new_languages[!is.na(new_languages)]
if (length(new_languages) > 0) {
new_language_map <- data.frame(
Original = new_languages,
Anonymized = paste0("lang", seq(nrow(language_key) + 1, nrow(language_key) + length(new_languages))),
stringsAsFactors = FALSE
)
language_key <- rbind(language_key, new_language_map)
}
# Step 5: Apply the replacements
component_data$LANGUAGE <- replace_language(component_data$LANGUAGE, language_key)
component_data$LANGUAGE1 <- replace_language(component_data$LANGUAGE1, language_key)
component_data$LANGUAGE2 <- replace_language(component_data$LANGUAGE2, language_key)
component_data_n$LANGUAGE <- replace_language(component_data_n$LANGUAGE, language_key)
scaling_factors_n$LANGUAGE <- replace_language(scaling_factors_n$LANGUAGE, language_key)
write.csv(subject_key, "subject_key.csv", row.names = FALSE)
write.csv(component_key, "component_key.csv", row.names = FALSE)
write.csv(nl_key, "no_lang_key.csv", row.names = FALSE)
write.csv(language_key, "language_key.csv", row.names = FALSE)
# ---- Save May files ----
setwd("../A. May data")
write.csv(component_data, "M23 component data.csv", row.names = FALSE)
write.csv(component_grade_boundaries, "M23 component grade boundaries.csv", row.names = FALSE)
write.csv(item_data, "M23 item data.csv", row.names = FALSE)
write.csv(subject_boundaries, "M23 subject boundaries.csv", row.names = FALSE)
# ---- Save November files ----
setwd("../C. November data")
write.csv(component_data_n, "N23 component data.csv", row.names = FALSE)
write.csv(component_data_n, "N23 component data.csv", row.names = FALSE)
write.csv(component_grade_boundaries_n, "N23 component grade boundaries.csv", row.names = FALSE)
write.csv(scaling_factors_n, "N23 scaling factors.csv", row.names = FALSE)
write.csv(subject_boundaries_n, "N23 subject boundaries.csv", row.names = FALSE)
library(tidyverse)
library(psych) # For alpha and omega
library(mice) # To impute missing grades
library(mirt) # For marginal reliability
library(MBESS) # For the GLB
library(Rcsdp) # Additional requirement for the GLB
library(purrr)
library(openxlsx)
library(caret)
library(data.table)
library(moments) # Skewness and kurtosis
# Read the data
data <- read.csv('A. Data/A. May Data/M23 component data.csv', header = TRUE, sep="")
setwd()
setwd('..\')
)
h
jkhbv
vgbRwQ[]
setwd('..\')
setwd()
setwd(here::here())
install.packages("here")
library(here)
setwd(here::here())
# Read the data
data <- read.csv('A. Data/A. May Data/M23 component data.csv', header = TRUE, sep="")
data_n <- read.csv('A. Data/C. November Data/N23 component Data.csv', header = F)
Compbounds <- fread('A. Data/A. May Data/M23 component grade boundaries.csv')
Subbounds <- read.csv('A. Data/A. May Data/M23 subject boundaries.csv')
Novcompbounds <- fread('A. Data/C. November Data/N23 component grade boundaries.csv')[,-1]
Novsubbounds <- read.csv('A. Data/C. November Data/N23 subject boundaries.csv')[,-1]
Realfailreasons <- fread('D. Results/A. Intermediate/Realfailreasons.csv')[,-1]
colnames(Realfailreasons)[1] <- 'CANDIDATE'
View(Realfailreasons)
View(data)
# Read the data
data <- read.csv('A. Data/A. May Data/M23 component data.csv', header = TRUE, sep=",")
View(data)
View(Compbounds)
# Reliability is calculated here then added to the preparation file
# 1.1 LOAD and TIDY the data ----
item_data <- read.csv('A. Data/A. May data/M23 Item Data.csv', header = TRUE, sep=",")
library(tidyverse)
library(psych) # For alpha and omega
library(mice) # To impute missing grades
library(mirt) # For marginal reliability
library(MBESS) # For the GLB
library(Rcsdp) # Additional requirement for the GLB
library(purrr)
library(openxlsx)
# Create wide data
item_wide <- item_data %>%
pivot_wider(names_from = ITEM, values_from = MARK)
# Split data by component
components <- split(item_wide, item_wide$NO_LANG_CODE)
components_back <- components # Save as backup
# 1.2 LOAD and TIDY MCQ answers ----
# Define a function to process each dataset
process_dataset <- function(data, dataset_name) {
# Keep columns starting with "N"
data <- data %>% select(starts_with("N"))
# Remove rows with only 0s
data <- data[rowSums(data != 0) > 0, ]
# Add 'NO_LANG_CODE' column
data <- data %>% mutate(NO_LANG_CODE = dataset_name) %>%
select(NO_LANG_CODE, everything())
# Add 'cand_anon' column with random candidate numbers
data <- data %>% mutate(cand_anon = sample(1:nrow(data), nrow(data), replace = FALSE))
# Convert to tibble
data <- as_tibble(data)
return(data)
}
# Define datasets and their names
datasets <- list(
nl79 = read.xlsx('A. Data/B. May MCQ/nl79.xlsx'),
nl350 = read.xlsx('A. Data/B. May MCQ/nl350.xlsx'),
nl663 = read.xlsx('A. Data/B. May MCQ/nl663.xlsx'),
nl914 = read.xlsx('A. Data/B. May MCQ/nl914.xlsx'),
nl373 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl373"),
nl908 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl908"),
nl860 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl860"),
nl221 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl221"),
nl1007 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl1007"),
nl527 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl527"),
nl441 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl441"),
nl584 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl584"),
nl983 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl983"),
nl177 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl177"),
nl637 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl637"),
nl830 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl830"),
nl208 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl208"),
nl942 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl942")
)
# 1.2 LOAD and TIDY MCQ answers ----
# Define a function to process each dataset
process_dataset <- function(data, dataset_name) {
# Keep columns starting with "N"
data <- data %>% select(starts_with("N"))
# Remove rows with only 0s
data <- data[rowSums(data != 0) > 0, ]
# Add 'NO_LANG_CODE' column
data <- data %>% mutate(NO_LANG_CODE = dataset_name) %>%
select(NO_LANG_CODE, everything())
# Add 'cand_anon' column with random candidate numbers
data <- data %>% mutate(cand_anon = sample(1:nrow(data), nrow(data), replace = FALSE))
# Convert to tibble
data <- as_tibble(data)
return(data)
}
# Define datasets and their names
datasets <- list(
nl79 = read.xlsx('A. Data/B. May MCQ/nl79.xlsx'),
nl350 = read.xlsx('A. Data/B. May MCQ/nl350.xlsx'),
nl663 = read.xlsx('A. Data/B. May MCQ/nl663.xlsx'),
nl914 = read.xlsx('A. Data/B. May MCQ/nl914.xlsx'),
nl373 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl373"),
nl908 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl908"),
nl860 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl860"),
nl221 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl221"),
nl1007 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl1007"),
nl527 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl527"),
nl441 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl441"),
nl584 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl584"),
nl983 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl983"),
nl177 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl177"),
nl637 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl637"),
nl830 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl830"),
nl208 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl208"),
nl942 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl942")
)
# 1.2 LOAD and TIDY MCQ answers ----
# Define a function to process each dataset
process_dataset <- function(data, dataset_name) {
# Keep columns starting with "N"
data <- data %>% select(starts_with("N"))
# Remove rows with only 0s
data <- data[rowSums(data != 0) > 0, ]
# Add 'NO_LANG_CODE' column
data <- data %>% mutate(NO_LANG_CODE = dataset_name) %>%
select(NO_LANG_CODE, everything())
# Add 'cand_anon' column with random candidate numbers
data <- data %>% mutate(cand_anon = sample(1:nrow(data), nrow(data), replace = FALSE))
# Convert to tibble
data <- as_tibble(data)
return(data)
}
# Define datasets and their names
datasets <- list(
nl79 = read.xlsx('A. Data/B. May MCQ/nl79.xlsx'),
nl350 = read.xlsx('A. Data/B. May MCQ/nl350.xlsx'),
nl663 = read.xlsx('A. Data/B. May MCQ/nl663.xlsx'),
nl914 = read.xlsx('A. Data/B. May MCQ/nl914.xlsx'),
nl373 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl373"),
nl908 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl908"),
nl860 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl860"),
nl221 = read.xlsx('A. Data/B. May MCQ/nl1.xlsx', sheet = "nl221"),
nl1007 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl1007"),
nl527 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl527"),
nl441 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl441"),
nl584 = read.xlsx('A. Data/B. May MCQ/nl2.xlsx', sheet = "nl584"),
nl983 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl983"),
nl177 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl177"),
nl637 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl637"),
nl830 = read.xlsx('A. Data/B. May MCQ/nl3.xlsx', sheet = "nl830"),
nl208 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl208"),
nl942 = read.xlsx('A. Data/B. May MCQ/nl4.xlsx', sheet = "nl942")
)
# Add MCQ items
for (name in names(datasets)) {
components[[name]] <- process_dataset(datasets[[name]], name)
}
View(Compbounds)
View(data)
View(item_data)
library(data.table)
# Data
data <- read.csv('A. Data/A. May Data/M23 component data.csv', header = TRUE, sep=",")
